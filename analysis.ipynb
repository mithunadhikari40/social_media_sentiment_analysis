{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Social Media Data\n",
    "\n",
    "This notebook walks through a complete sentiment analysis project on social media data. We will cover the entire pipeline from data collection to model evaluation and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup: Importing Libraries\n",
    "\n",
    "First, we import all the necessary libraries for data manipulation, text preprocessing, modeling, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mithun/Documents/education/masters_in_computer_application_throug_mysore_university/last_semester/project/social_media_analysis/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mithun/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/mithun/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd # Used for creating and manipulating dataframes\n",
    "import numpy as np # Used for numerical operations\n",
    "\n",
    "# Import .env files to load environement varialbles.\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Text preprocessing and feature extraction\n",
    "import re # Regular expressions for cleaning text\n",
    "import nltk # Natural Language Toolkit for stopwords\n",
    "from nltk.corpus import stopwords # List of common words to remove\n",
    "from nltk.stem import WordNetLemmatizer # Lemmatization to reduce words to their base form\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # TF-IDF for text representation\n",
    "import spacy # For more advanced text processing\n",
    "\n",
    "# Machine Learning models\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV # For splitting data and hyperparameter tuning\n",
    "from sklearn.naive_bayes import MultinomialNB # Naive Bayes classifier\n",
    "from sklearn.svm import SVC # Support Vector Machine classifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix # Evaluation metrics\n",
    "\n",
    "# Deep Learning models (using PyTorch)\n",
    "import torch # Main PyTorch library\n",
    "from torch.utils.data import DataLoader, TensorDataset # For handling data in PyTorch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification # BERT model and tokenizer\n",
    "from torch.optim import AdamW # AdamW from torch directly\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt # For creating static plots\n",
    "import seaborn as sns # For more attractive statistical plots\n",
    "from wordcloud import WordCloud # For generating word clouds\n",
    "import plotly.express as px # For interactive plots\n",
    "\n",
    "# Saving models and files\n",
    "import os # For interacting with the operating system (e.g., creating directories)\n",
    "import joblib # For saving and loading scikit-learn models\n",
    "import json # For saving results to a JSON file\n",
    "\n",
    "# Download necessary NLTK data (if not already present)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style('whitegrid')\n",
    "print(\"Step 1 done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Collection\n",
    "\n",
    "In this step, we collect the data for our analysis. The ideal source is live data from a social media platform like Twitter. However, since API keys cannot be shared, we provide two options:\n",
    "\n",
    "1.  **Live Data Collection (Placeholder):** Code using `tweepy` to fetch tweets. You would need to insert your own Twitter API credentials to run this.\n",
    "2.  **Sample CSV Fallback:** If API keys are unavailable, we load data from a pre-made CSV file (`sample_tweets.csv`). **This is the default method for this notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to fetch 100 live tweets for the query: 'AI ethics'...\n"
     ]
    },
    {
     "ename": "TooManyRequests",
     "evalue": "429 Too Many Requests\nToo Many Requests",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTooManyRequests\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempting to fetch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m live tweets for the query: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m client = tweepy.Client(bearer_token)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch_recent_tweets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m tweets_data = []\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.data:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/education/masters_in_computer_application_throug_mysore_university/last_semester/project/social_media_analysis/venv/lib/python3.12/site-packages/tweepy/client.py:1276\u001b[39m, in \u001b[36mClient.search_recent_tweets\u001b[39m\u001b[34m(self, query, user_auth, **params)\u001b[39m\n\u001b[32m   1184\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"search_recent_tweets( \\\u001b[39;00m\n\u001b[32m   1185\u001b[39m \u001b[33;03m    query, *, end_time=None, expansions=None, max_results=None, \\\u001b[39;00m\n\u001b[32m   1186\u001b[39m \u001b[33;03m    media_fields=None, next_token=None, place_fields=None, \\\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1273\u001b[39m \u001b[33;03m.. _Academic Research Project: https://developer.twitter.com/en/docs/projects\u001b[39;00m\n\u001b[32m   1274\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1275\u001b[39m params[\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m] = query\n\u001b[32m-> \u001b[39m\u001b[32m1276\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1277\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/2/tweets/search/recent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1278\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint_parameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1279\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mend_time\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexpansions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_results\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmedia.fields\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1280\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnext_token\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mplace.fields\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpoll.fields\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1281\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msince_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msort_order\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstart_time\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtweet.fields\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1282\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muntil_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser.fields\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   1283\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTweet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_auth\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_auth\u001b[49m\n\u001b[32m   1284\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/education/masters_in_computer_application_throug_mysore_university/last_semester/project/social_media_analysis/venv/lib/python3.12/site-packages/tweepy/client.py:129\u001b[39m, in \u001b[36mBaseClient._make_request\u001b[39m\u001b[34m(self, method, route, params, endpoint_parameters, json, data_type, user_auth)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_make_request\u001b[39m(\n\u001b[32m    124\u001b[39m     \u001b[38;5;28mself\u001b[39m, method, route, params={}, endpoint_parameters=(), json=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    125\u001b[39m     data_type=\u001b[38;5;28;01mNone\u001b[39;00m, user_auth=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    126\u001b[39m ):\n\u001b[32m    127\u001b[39m     request_params = \u001b[38;5;28mself\u001b[39m._process_params(params, endpoint_parameters)\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_auth\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_auth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_type \u001b[38;5;129;01mis\u001b[39;00m requests.Response:\n\u001b[32m    133\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/education/masters_in_computer_application_throug_mysore_university/last_semester/project/social_media_analysis/venv/lib/python3.12/site-packages/tweepy/client.py:115\u001b[39m, in \u001b[36mBaseClient.request\u001b[39m\u001b[34m(self, method, route, params, json, user_auth)\u001b[39m\n\u001b[32m    113\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(method, route, params, json, user_auth)\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m TooManyRequests(response)\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code >= \u001b[32m500\u001b[39m:\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m TwitterServerError(response)\n",
      "\u001b[31mTooManyRequests\u001b[39m: 429 Too Many Requests\nToo Many Requests"
     ]
    }
   ],
   "source": [
    "# --- How to Modify ---\n",
    "# USE_LIVE_DATA: Set to True to use the live Twitter API, or False to use the sample CSV.\n",
    "# csv_path: The file path for the sample data.\n",
    "# query: The search term for fetching live tweets (e.g., 'Python programming').\n",
    "# max_results: The number of live tweets to fetch (between 10 and 100).\n",
    "\n",
    "USE_LIVE_DATA = True\n",
    "csv_path = 'sample_tweets.csv'\n",
    "query = 'AI ethics'\n",
    "max_results = 100\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "bearer_token = os.getenv(\"BEARER_TOKEN\")\n",
    "\n",
    "if USE_LIVE_DATA:\n",
    "    if not bearer_token or bearer_token == \"YOUR_BEARER_TOKEN_HERE\":\n",
    "        raise ValueError(\"Twitter Bearer Token not found. Please set it in your .env file.\")\n",
    "\n",
    "    import tweepy\n",
    "\n",
    "    print(f\"Attempting to fetch {max_results} live tweets for the query: '{query}'...\")\n",
    "    client = tweepy.Client(bearer_token)\n",
    "    response = client.search_recent_tweets(query=query, max_results=max_results)\n",
    "\n",
    "    tweets_data = []\n",
    "    if response.data:\n",
    "        for tweet in response.data:\n",
    "            # For simplicity, we assign a 'neutral' sentiment to all fetched tweets.\n",
    "            # In a real-world scenario, these would need to be labeled.\n",
    "            tweets_data.append({'tweet': tweet.text, 'sentiment': 'neutral'})\n",
    "        df = pd.DataFrame(tweets_data)\n",
    "        print(f\"Successfully fetched {len(df)} tweets.\")\n",
    "    else:\n",
    "        print(\"No tweets found for the query. Falling back to the sample CSV.\")\n",
    "        df = pd.read_csv(csv_path)\n",
    "else:\n",
    "    print(\"Using sample data from sample_tweets.csv\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Data Visualization: Sentiment Distribution\n",
    "\n",
    "Let's visualize the distribution of sentiments in our dataset. This gives us a first look at the balance of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gw/kf_z97q53554pcmvdnq72nsc0000gp/T/ipykernel_34920/2121833167.py:6: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(x='sentiment', data=df, palette='viridis')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if df is not None and 'sentiment' in df.columns:\n",
    "    # Create a figure for the plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # Create a bar plot of sentiment counts\n",
    "    sns.countplot(x='sentiment', data=df, palette='viridis')\n",
    "    \n",
    "    # Add titles and labels for clarity\n",
    "    plt.title('Distribution of Sentiments in the Dataset', fontsize=16)\n",
    "    plt.xlabel('Sentiment', fontsize=12)\n",
    "    plt.ylabel('Number of Tweets', fontsize=12)\n",
    "    \n",
    "    # Save the plot to the 'plots' directory\n",
    "    if not os.path.exists('plots'):\n",
    "        os.makedirs('plots') # Create the directory if it doesn't exist\n",
    "    plt.savefig('plots/sentiment_distribution.png') # Save the figure\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Text Representation: Converting Text to Numbers\n",
    "\n",
    "Machine learning models can't understand raw text. We need to convert our cleaned text data into numerical vectors. We will explore two popular methods:\n",
    "\n",
    "1.  **TF-IDF (Term Frequency-Inverse Document Frequency):** A classical feature extraction technique that represents text as a matrix of word counts, weighted by their importance.\n",
    "2.  **Transformer Embeddings (BERT):** A modern technique using deep learning to create dense, context-aware vector representations of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Splitting Data into Training and Testing Sets\n",
    "\n",
    "Before we create text representations, we must split our data. This ensures that our model is evaluated on data it has never seen before, giving us a true measure of its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- How to Modify ---\n",
    "# test_size: The proportion of the dataset to allocate to the test set. A common value is 0.2 (20%). Changing this affects how much data the model trains on vs. is tested on. More training data can lead to a better model, but a smaller test set might give a less reliable evaluation.\n",
    "# random_state: A seed for reproducibility. Setting this ensures you get the same train/test split every time you run the code.\n",
    "\n",
    "if df is not None:\n",
    "    # Define features (X) and target (y)\n",
    "    X = df['cleaned_tweet'] # The cleaned text data\n",
    "    y = df['sentiment']   # The sentiment labels\n",
    "    \n",
    "    # Perform the split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2,      # Use 20% of the data for testing\n",
    "        random_state=42,    # Ensures the split is the same every time\n",
    "        stratify=y          # Ensures the distribution of sentiments is the same in train and test sets\n",
    "    )\n",
    "    \n",
    "    # Print the shapes of the resulting datasets\n",
    "    print(f'Training data shape: {X_train.shape}')\n",
    "    print(f'Testing data shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Method 1: TF-IDF Vectorization\n",
    "\n",
    "TF-IDF stands for Term Frequency-Inverse Document Frequency. It evaluates how relevant a word is to a document in a collection of documents.\n",
    "-   **Term Frequency (TF):** How often a word appears in a document.\n",
    "-   **Inverse Document Frequency (IDF):** The inverse of how many documents contain the word. This gives higher weight to rarer words.\n",
    "\n",
    "The TF-IDF score is the product of these two, resulting in a sparse matrix where each row is a tweet and each column is a unique word from our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- How to Modify ---\n",
    "# ngram_range: The range of n-grams to consider. (1, 1) means only single words (unigrams). (1, 2) means both unigrams and bigrams (two-word phrases). Using bigrams can capture more context but dramatically increases the number of features.\n",
    "# max_features: The maximum number of top features (words) to keep. This helps control the dimensionality of the feature space.\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),  # Consider both single words and two-word phrases\n",
    "    max_features=5000    # Limit the vocabulary size to the top 5000 features\n",
    ")\n",
    "\n",
    "# Fit the vectorizer on the training data and transform it\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Only transform the test data (using the vocabulary from the training data)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Print the shape of the resulting TF-IDF matrices\n",
    "print(f'Shape of TF-IDF training matrix: {X_train_tfidf.shape}')\n",
    "print(f'Shape of TF-IDF testing matrix: {X_test_tfidf.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. Method 2: Transformer Embeddings (BERT)\n",
    "\n",
    "BERT (Bidirectional Encoder Representations from Transformers) is a state-of-the-art model that generates dense, context-aware embeddings. Unlike TF-IDF, which treats words in isolation, BERT understands the meaning of a word based on its surrounding words.\n",
    "\n",
    "**Key Differences:**\n",
    "| Feature | TF-IDF | BERT Embeddings |\n",
    "|---|---|---|\n",
    "| **Representation** | Sparse matrix (mostly zeros) | Dense vector (meaningful numbers) |\n",
    "| **Context** | No, treats words independently | Yes, understands context (e.g., 'bank' as in river vs. finance) |\n",
    "| **Vector Size** | Large (equals vocabulary size) | Small and fixed (e.g., 768 dimensions) |\n",
    "| **Computational Cost**| Low | High |\n",
    "\n",
    "We will not generate the embeddings separately. Instead, the tokenization and embedding process will be handled directly by the BERT model during the training phase in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the pre-trained BERT tokenizer to prepare the data for the model.\n",
    "# This step is just a demonstration of how the tokenizer works.\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Example of tokenizing a single sentence\n",
    "sample_text = \"This is a sample sentence for BERT.\"\n",
    "encoded_sample = tokenizer.encode_plus(\n",
    "    sample_text,\n",
    "    add_special_tokens=True, # Add '[CLS]' and '[SEP]' tokens\n",
    "    max_length=32,           # Pad or truncate to a fixed length\n",
    "    padding='max_length',\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt'      # Return PyTorch tensors\n",
    ")\n",
    "\n",
    "print(\"Input IDs:\", encoded_sample['input_ids'])\n",
    "print(\"Attention Mask:\", encoded_sample['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Training\n",
    "\n",
    "Now we will train and evaluate three different models on our preprocessed data. We'll start with two classical machine learning models using the TF-IDF features and then move to a deep learning model using BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Model 1: Multinomial Naive Bayes\n",
    "\n",
    "Naive Bayes is a probabilistic classifier based on Bayes' theorem with a 'naive' assumption of conditional independence between features. It's computationally efficient and works well for text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- How to Modify ---\n",
    "# alpha (smoothing parameter): A value added to the numerators for smoothing. It prevents zero probabilities for features not seen in the training data. A higher alpha makes the model less sensitive to the training data.\n",
    "\n",
    "# Initialize the Naive Bayes model\n",
    "nb_model = MultinomialNB(alpha=1.0) # alpha=1.0 is a common default (Laplace smoothing)\n",
    "\n",
    "# Train the model on the TF-IDF training data\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "print(f'Naive Bayes Accuracy: {accuracy_nb:.4f}')\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(nb_model, 'models/naive_bayes_model.pkl')\n",
    "print(\"Naive Bayes model saved to models/naive_bayes_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Model 2: Support Vector Machine (SVM)\n",
    "\n",
    "SVMs are powerful classifiers that find the optimal hyperplane separating data points of different classes. They are particularly effective in high-dimensional spaces, like the one created by TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- How to Modify ---\n",
    "# C (Regularization parameter): Controls the trade-off between achieving a low training error and a low testing error. A high C value gives more weight to the training data, potentially leading to overfitting.\n",
    "# kernel: The type of kernel to use. 'linear' is often a good start for text data. 'rbf' is another popular choice.\n",
    "# gamma: Kernel coefficient for 'rbf'. 'scale' is a good default.\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm_model = SVC(C=1.0, kernel='linear', random_state=42) # C=1.0 is a standard default\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f'SVM Accuracy: {accuracy_svm:.4f}')\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(svm_model, 'models/svm_model.pkl')\n",
    "print(\"SVM model saved to models/svm_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3. Model 3: Fine-Tuning a BERT Transformer\n",
    "\n",
    "For our third model, we will fine-tune a pre-trained BERT model. This involves taking a powerful, general-purpose language model and training it further on our specific sentiment analysis task. This process is more computationally intensive and requires a GPU for reasonable training times.\n",
    "\n",
    "**Note:** Training this model can be slow without a GPU. For this notebook, we will run it for just one epoch on our small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- How to Modify ---\n",
    "# learning_rate: How much the model's weights are updated during training. A smaller value (e.g., 2e-5) is typical for fine-tuning.\n",
    "# batch_size: The number of samples processed before the model is updated. A smaller batch size requires less memory.\n",
    "# epochs: The number of times the model will see the entire training dataset. More epochs can lead to better performance but also overfitting.\n",
    "\n",
    "# First, we need to map our text labels to integers\n",
    "label_map = {label: i for i, label in enumerate(df['sentiment'].unique())}\n",
    "y_train_int = y_train.map(label_map)\n",
    "y_test_int = y_test.map(label_map)\n",
    "\n",
    "# Tokenize the text data for BERT\n",
    "def tokenize_for_bert(texts):\n",
    "    return tokenizer(texts.tolist(), padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "train_encodings = tokenize_for_bert(X_train)\n",
    "test_encodings = tokenize_for_bert(X_test)\n",
    "\n",
    "# Create PyTorch datasets\n",
    "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], torch.tensor(y_train_int.tolist()))\n",
    "test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], torch.tensor(y_test_int.tolist()))\n",
    "\n",
    "# Initialize the BERT model for sequence classification\n",
    "bert_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_map))\n",
    "\n",
    "# Set up the data loaders\n",
    "batch_size = 4 # Small batch size for CPU\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = AdamW(bert_model.parameters(), lr=5e-5) # AdamW is a common optimizer for transformers\n",
    "\n",
    "# --- Training Loop ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Use GPU if available\n",
    "bert_model.to(device)\n",
    "bert_model.train() # Set the model to training mode\n",
    "\n",
    "epochs = 1 # For demonstration, we only train for one epoch\n",
    "for epoch in range(epochs):\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad() # Clear previous gradients\n",
    "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "        outputs = bert_model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss # Get the loss\n",
    "        loss.backward() # Backpropagate the loss\n",
    "        optimizer.step() # Update the weights\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}')\n",
    "\n",
    "print(\"BERT model training complete.\")\n",
    "\n",
    "# Save the fine-tuned BERT model\n",
    "torch.save(bert_model.state_dict(), 'models/bert_model.pth')\n",
    "print(\"BERT model saved to models/bert_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model Evaluation\n",
    "\n",
    "After training, we need to evaluate our models to see how well they perform on unseen data. We will use several metrics:\n",
    "-   **Accuracy:** The proportion of correctly classified tweets.\n",
    "-   **Precision:** The proportion of positive predictions that were actually correct. (TP / (TP + FP))\n",
    "-   **Recall:** The proportion of actual positives that were identified correctly. (TP / (TP + FN))\n",
    "-   **F1-Score:** The harmonic mean of precision and recall, providing a single score that balances both.\n",
    "-   **Confusion Matrix:** A table that visualizes the performance of a classifier, showing the counts of true vs. predicted labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1. Evaluating the BERT Model\n",
    "\n",
    "First, we need a function to get predictions from our fine-tuned BERT model, as the process is different from scikit-learn models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get predictions from the BERT model\n",
    "def get_bert_predictions(model, data_loader):\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    predictions = []\n",
    "    with torch.no_grad(): # Disable gradient calculation for inference\n",
    "        for batch in data_loader:\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1).flatten()\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "    return predictions\n",
    "\n",
    "# Create a DataLoader for the test set (no shuffling needed)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Get predictions for the test set\n",
    "y_pred_bert_int = get_bert_predictions(bert_model, test_loader)\n",
    "\n",
    "# We need to map the integer predictions back to string labels for comparison\n",
    "reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "y_pred_bert = [reverse_label_map[p] for p in y_pred_bert_int]\n",
    "\n",
    "accuracy_bert = accuracy_score(y_test, y_pred_bert)\n",
    "print(f'BERT Model Accuracy: {accuracy_bert:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2. Comparing All Models\n",
    "\n",
    "Let's compile the key metrics for all three models into a single table for easy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary to store the evaluation results\n",
    "evaluation_results = {}\n",
    "\n",
    "# Define the models and their predictions\n",
    "models = {\n",
    "    'Naive Bayes': y_pred_nb,\n",
    "    'SVM': y_pred_svm,\n",
    "    'BERT': y_pred_bert\n",
    "}\n",
    "\n",
    "# Calculate metrics for each model\n",
    "for model_name, y_pred in models.items():\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted') # Use 'weighted' for multiclass\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    evaluation_results[model_name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# Create a DataFrame for a clean display\n",
    "results_df = pd.DataFrame(evaluation_results).T # Transpose for better readability\n",
    "display(results_df)\n",
    "\n",
    "# Save the results to a JSON file\n",
    "results_df.to_json('results/evaluation_results.json', orient='index', indent=4)\n",
    "print(\"Evaluation results saved to results/evaluation_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3. Visualizing Performance with Confusion Matrices\n",
    "\n",
    "A confusion matrix provides a detailed breakdown of correct and incorrect classifications for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot a confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'Confusion Matrix for {model_name}', fontsize=16)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.savefig(f'plots/confusion_matrix_{model_name.replace(\" \", \"_\").lower()}.png') # Save the plot\n",
    "    plt.show()\n",
    "\n",
    "# Get the unique labels for plotting\n",
    "class_labels = sorted(y_test.unique())\n",
    "\n",
    "# Plot the confusion matrix for each model\n",
    "for model_name, y_pred in models.items():\n",
    "    plot_confusion_matrix(y_test, y_pred, model_name, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Hyperparameter Tuning with GridSearchCV\n",
    "\n",
    "The performance of many machine learning models depends heavily on their hyperparameters. Manually tuning them can be tedious. `GridSearchCV` is a technique that automates this process by exhaustively searching through a specified grid of parameter values to find the best combination.\n",
    "\n",
    "Here, we will tune our SVM model to see if we can improve its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- How to Modify ---\n",
    "# param_grid: This dictionary defines the hyperparameter space to search. You can add more parameters (e.g., 'gamma') or more values to explore.\n",
    "# cv (Cross-Validation): The number of folds to use for cross-validation. 5 is a common choice. More folds provide a more robust evaluation but increase computation time.\n",
    "# n_jobs: The number of CPU cores to use. Set to -1 to use all available cores, which can significantly speed up the search.\n",
    "\n",
    "# Define the parameter grid for the SVM\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10], # Different values for the regularization parameter\n",
    "    'kernel': ['linear', 'rbf'] # Different kernel types to try\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    SVC(random_state=42), # The model to tune\n",
    "    param_grid,           # The parameters to search\n",
    "    cv=3,                 # Use 3-fold cross-validation\n",
    "    n_jobs=-1,            # Use all available CPU cores\n",
    "    verbose=2             # Show progress\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV on the training data\n",
    "print(\"Starting GridSearchCV for SVM...\")\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "print(f\"\\nBest Parameters found: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate the best model found by GridSearchCV on the test set\n",
    "best_svm = grid_search.best_estimator_\n",
    "y_pred_best_svm = best_svm.predict(X_test_tfidf)\n",
    "accuracy_best_svm = accuracy_score(y_test, y_pred_best_svm)\n",
    "print(f\"Test set accuracy of the best SVM model: {accuracy_best_svm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Visualization of Results\n",
    "\n",
    "Visualizations help us understand the data and our model's results more intuitively. We will create word clouds to see the most frequent words for different sentiments and a chart to analyze sentiment trends over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1. Word Clouds for Positive and Negative Sentiments\n",
    "\n",
    "Word clouds are a great way to visualize the most prominent words in a body of text. We will generate one for positive tweets and one for negative tweets to see which words are most associated with each sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate and plot a word cloud\n",
    "def generate_word_cloud(text, title):\n",
    "    wordcloud = WordCloud(\n",
    "        width=800, \n",
    "        height=400, \n",
    "        background_color='white'\n",
    "    ).generate(text)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off') # Hide the axes\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.savefig(f'plots/{title.replace(\" \", \"_\").lower()}.png')\n",
    "    plt.show()\n",
    "\n",
    "# Separate text by sentiment\n",
    "positive_text = ' '.join(df[df['sentiment'] == 'positive']['cleaned_tweet'])\n",
    "negative_text = ' '.join(df[df['sentiment'] == 'negative']['cleaned_tweet'])\n",
    "\n",
    "# Generate word clouds\n",
    "if positive_text:\n",
    "    generate_word_cloud(positive_text, 'Most Frequent Words in Positive Tweets')\n",
    "if negative_text:\n",
    "    generate_word_cloud(negative_text, 'Most Frequent Words in Negative Tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2. Trend of Sentiments Over Time\n",
    "\n",
    "Analyzing how sentiments change over time can reveal important patterns. Since our sample dataset does not have timestamps, we will create some dummy dates to demonstrate how to create a time-series plot.\n",
    "\n",
    "**Note:** For a real-world application, you would use the actual timestamps from the social media data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy timestamps for demonstration\n",
    "df['timestamp'] = pd.to_datetime(pd.date_range(start='2023-01-01', periods=len(df), freq='h'))\n",
    "\n",
    "# Group by day and sentiment, then count the occurrences\n",
    "sentiment_over_time = df.groupby([df['timestamp'].dt.date, 'sentiment']).size().unstack(fill_value=0)\n",
    "\n",
    "# Create the line plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sentiment_over_time.plot(kind='line', ax=plt.gca())\n",
    "plt.title('Trend of Sentiments Over Time (Dummy Data)', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Number of Tweets', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Sentiment')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/sentiment_trends.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Final Dashboard and Summary\n",
    "\n",
    "This final section provides a dashboard-style summary of our key findings. It combines the most important visualizations and metrics into a single view for a quick, high-level understanding of the project's results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with subplots for the dashboard\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "fig.suptitle('Sentiment Analysis Project Dashboard', fontsize=24, y=1.02)\n",
    "\n",
    "# 1. Sentiment Distribution (Pie Chart)\n",
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "axes[0, 0].pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=140, colors=px.colors.qualitative.Pastel)\n",
    "axes[0, 0].set_title('Overall Sentiment Distribution', fontsize=16)\n",
    "\n",
    "# 2. Model Performance Comparison (Bar Chart)\n",
    "results_df['Accuracy'].plot(kind='bar', ax=axes[0, 1], color=px.colors.qualitative.Vivid)\n",
    "axes[0, 1].set_title('Model Accuracy Comparison', fontsize=16)\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].tick_params(axis='x', rotation=0)\n",
    "axes[0, 1].set_ylim(0, 1.1)\n",
    "for i, v in enumerate(results_df['Accuracy']):\n",
    "    axes[0, 1].text(i, v + 0.02, f'{v:.2f}', ha='center')\n",
    "\n",
    "# 3. Confusion Matrix of the Best Model (SVM)\n",
    "best_model_name = results_df['Accuracy'].idxmax()\n",
    "y_pred_best = models[best_model_name]\n",
    "cm = confusion_matrix(y_test, y_pred_best, labels=class_labels)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=class_labels, yticklabels=class_labels, ax=axes[1, 0])\n",
    "axes[1, 0].set_title(f'Confusion Matrix for Best Model: {best_model_name}', fontsize=16)\n",
    "axes[1, 0].set_xlabel('Predicted')\n",
    "axes[1, 0].set_ylabel('True')\n",
    "\n",
    "# 4. Key Insights (Text)\n",
    "axes[1, 1].axis('off') # Hide the axes for the text block\n",
    "insights = f\"\"\"\\n\n",
    "**Key Insights:**\\n\\n\n",
    "1. **Sentiment Balance:** The dataset is fairly balanced,\\n\n",
    "   with {pos_pct:.1f}% positive, {neg_pct:.1f}% negative, and {neu_pct:.1f}% neutral tweets.\\n\\n\n",
    "2. **Best Performing Model:** The **{best_model}** model achieved the\\n\n",
    "   highest accuracy of **{best_acc:.2f}**.\\n\\n\n",
    "3. **Common Words:**\\n\n",
    "   - Positive tweets often contain words like 'love', 'best', 'great'.\\n\n",
    "   - Negative tweets feature words like 'bad', 'hate', 'problem'.\\n\\n\n",
    "4. **Model Behavior:** The confusion matrix shows that the\\n\n",
    "   model is most effective at identifying positive and negative\\n\n",
    "   sentiments but sometimes struggles with neutral tweets.\n",
    "\"\"\".format(\n",
    "    pos_pct=sentiment_counts.get('positive', 0) / len(df) * 100,\n",
    "    neg_pct=sentiment_counts.get('negative', 0) / len(df) * 100,\n",
    "    neu_pct=sentiment_counts.get('neutral', 0) / len(df) * 100,\n",
    "    best_model=best_model_name,\n",
    "    best_acc=results_df['Accuracy'].max()\n",
    ")\n",
    "axes[1, 1].text(0, 0.5, insights, va='center', fontsize=12, wrap=True)\n",
    "\n",
    "# Adjust layout and save the dashboard\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/final_dashboard.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
